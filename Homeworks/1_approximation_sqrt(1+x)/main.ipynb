{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Approximation of $\\sqrt{1+x}$</div>\n",
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow versio:  1.14.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(['ggplot'])\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "\n",
    "import tensorflow as tf\n",
    "print('tensorflow versio: ', tf.__version__)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of data points \n",
    "n = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random(n).reshape((n, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.sqrt(1+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFMhJREFUeJzt3X+QXlV9x/H35m5KGaMww2ODa3SUEZtahNFC41BHYpUppAxpKhyKoIIkaZpBBg1FEBAtIoJG1ImYJmlMAcUef0QyThyHaUXaIozWNuO0TTs02LquJCQ4cRgpDTfbP3aBkOzuc/fe8/y69/2a2YFnn3vP8z15ks+ePfc85w6Nj48jSaqXOb0uQJKUnuEuSTVkuEtSDRnuklRDhrsk1ZDhLkk1ZLhLUg0Z7pJUQ4a7JNXQcA9f24/GSlI5Q+0O6GW4MzY2VrmNVqvF3r17E1QzGOxvfTWpr2B/yxoZGSl0nNMyklRDhrsk1ZDhLkk1ZLhLUg0Z7pJUQ4a7JNWQ4S5JNWS4S1INGe6SVEOGuyTVkOEuSTXU071lJKnu8vu2wdc2s/vgQZgzB857L9mZ53b8dQ13SeqA/JoVsG/3C7958CDETeTQ8YB3WkaSEsrX3kC+4twjg/1QcVPH63DkLkkJ5Pdt60poF2W4S1IF+cPfg01re13GEQx3SSopX9H5C6NltQ33EMJm4BxgT4zxpBmOOw14CLggxvi1dCVKUn/JVy6D8bx8A9ncdMVMo8jIfQuwDrhzugNCCBlwK/CdNGVJUv9JMlLP5pKt/3r1dtpoG+4xxgdCCK9qc9j7gK8Dp6UoSpL6Sf7+d8GT+yu3k23clqCaYirPuYcQXg4sA34fw11SjUy5Vr2EbOO2rt8QPMUF1c8AH4wx5iGEGQ8MIawEVgLEGGm1WpVffHh4OEk7g8L+1leT+gr93d/df3o+7PlZ5Xbmb33wuf/vdn+HxsfH2x40OS3zrakuqIYQHgWGJh+2gF8BK2OM32zT7PjY2Njsqp1Ct38a9pr9ra8m9RX6s7/52htg547K7Uw1/ZKqvyMjI/B85k6r8sg9xvjqZ/8/hLCFiR8C7YJdkvrGwccfY/xDKyu3M/TxDcx56fEJKqquyFLIe4DFQCuEMArcCMwFiDGu72h1ktRhSVbAhOVd2QxsNoqslrmwaGMxxksqVSNJXZIk1E9YSHbtbdXb6QA/oSqpUeoe6s8y3CU1QuVPlQIMZWQbtqYpqMMMd0m1lmS3xqOOJlv3N2kK6hLDXVItpdqCt5ufKk3JcJdUOynm1Qc11J9luEuqjSQXSxctJlv+gert9JjhLmng5avPhwNPV2ukJqH+LMNd0sBKslvjAF4sLcJwlzRwmn6xtAjDXdLASHW/0jqH+rMMd0kDwRUws2O4S+prSVbALF9DtuiM6u0MEMNdUl/Kr7oU9u+r1sgA7AHTKYa7pL6S5GLpvGPIbr8rTUEDynCX1BfynT+GtddVa6SmyxrLMNwl9ZwXS9Mz3CX1jKHeOYa7pK7LV5/P7qrbBSwJZMsuTlNQDRnukromv+Kd8NST1RpZeArZmpvSFFRjhrukjkvzydIhso33JqmnCQx3SR1VeV7dFTClGO6SOsKLpb1luEtKKr/8Anj6qWqNLF5CdtGqNAU1lOEuKYl8692wPVZrxBUwyRjukiqrPAUzlJFt2JqmGAGGu6QKnFfvX4a7pFlLsV59/tYH2bt3b6KKdDjDXVJh+S1Xw66d1RrxYmlXGO6S2kqyY+P8BWQfuyNNQWrLcJc0o8rz6g2+YUYvGe6SpuTF0sFmuEt6gfz61bB7tFIbhnrvzel1AZL6w8HHH5sYrVcJ9kWLDfY+4chdUvUpmOPmk31iY5pilIThLjVYvuodkB+o1IYj9f5kuEsNlK+9AXbuqNSGod7f2oZ7CGEzcA6wJ8Z40hTPLwVuAg4CzwBXxhj/IXWhkqpLsl79lEVkl1dsQx1XZOS+BVgH3DnN838LbIsxjocQTgYisDBNeZJScb16s7QN9xjjAyGEV83w/KEbTLwIGE9Ql6REnFdvpiRz7iGEZcAtwG8Af5iiTUnV5NesgH27K7VhqA+uJOEeY9wKbA0hvIWJ+fe3T3VcCGElsHLyHFqtVuXXHh4eTtLOoLC/9ZWyr7uXnV7p/HlXfpQXnXFmklqm06T3Frrf36Hx8fazKJPTMt+a6oLqFMc+CpwWY2y3l+f42NhYoSJn0mq1GrVtqP2trxR9rTyvfvQ8ss99uVobBTXpvYV0/R0ZGQEYandc5ZF7COE1wH9NXlB9I/BrwL6q7UoqLsV9S52CqZciSyHvARYDrRDCKHAjMBcgxrgeeAfw7hDCAeAp4IIYoxdVpS5wvbqmU2S1zIVtnr8VuDVZRZIKqTwF400zas1PqEoDpvIUjDfNaATDXRoQ+aZPw8P3V2rDKZjmMNylAVB1CsZQbx7DXepj+YqlVPrQ95JAtuziZPVocBjuUh/KP3oljO6q0MIQ2cZ7k9WjwWO4S33EeXWlYrhLfaLqlgGE5WRnVr+pterBcJd6LL/qUthf4UPdbsWrKRjuUo/kW++G7bF8A/OOIbv9rnQFqVYMd6kHXNqoTjPcpS7KV58PB54u38DCU8jW3JSuINWW4S51Qb7uZtjxcKU2HK1rNgx3qcOcglEvGO5Sh1S+d+kpi8guvy5dQWoUw11KLP/Serh/e/kG5h5FdsdX0xWkRjLcpYScglG/MNylBPIr3glPPVm+gTU3M//Nb23UPUXVWYa7VEF+y9Wwa2f5BrxxhjrEcJdKcgpG/cxwl2ap8mh9zc1kC1+friBpCoa7VFDlvWAWnEB242fSFSTNwHCXCnAKRoPGcJdmUDXUnYJRrxju0hTy+7ZB3FS+AVfBqMcMd+kwTsGoDgx3aVLlKZjla8gWnZGmGKkiw13C0brqx3BXo1XdNsBQV78y3NVIlW+e4Xa86nOGuxqn0hSM2/FqQBjuagzn1dUkhrtqL197A+zcUb6BsJzszIoraaQuM9xVa5VG6/OOIbv9rnTFSF1kuKuWqo7WnYLRoJvT6wKklPKdP54YrZcN9uPmG+yqBUfuqg0vmErPaxvuIYTNwDnAnhjjSVM8fxHwwcmHTwJ/FmOscPVKmp38+tWwe7T0+Ya66qjItMwW4KwZnn8UOCPGeDJwE7AhQV1SIfmKc8sH+4ITDHbVVtuRe4zxgRDCq2Z4/sFDHj4ELEhQlzSj/KpLYf++0ucb6qq71HPulwHfnu7JEMJKYCVAjJFWq1X5BYeHh5O0MyjsL+xednrp9rK3nEXr/R+uWlZH+N7WW7f7myzcQwhvZSLc3zzdMTHGDTw/bTO+d+/eyq/barVI0c6gaHJ/89Xnw4GnyzV09Dyyz30ZoG///Jr83jZBqv6OjIwUOi5JuIcQTgY2AWfHGMv/rixNIf/Serh/e+nznYJRE1UO9xDCK4FvAO+KMf5n9ZKk51WZgnGTLzVZkaWQ9wCLgVYIYRS4EZgLEGNcD3wYOA64I4QA8EyM8dROFaxmyFcsBcZLn+9oXU03ND5e/h9QReNjY2OVG3Hern4qfRhpgPdZb8J7eyj7W87knPtQu+P8hKr6RqXljYdcMJVkuKsP5Dt/DGvLj7adgpGOZLirpypNwZywkOza29IVI9WI4a6ecEteqbMMd3VdldH60Mc3MOelxyesRqonw11dk99yNezaWfp8R+tScYa7usLRutRdhrs6qtJe60MZ87/x941aCy2lYrirI/L7tkHcVPp8p2Ckagx3JVdpeeP8BWQfuyNdMVJDGe5KJt96N2yPpc93tC6lY7griUqj9YWnkK25KV0xkgx3VVNpeaNb8kodY7irtEqj9eVryBadka4YSS9guGvWKu3eOO8YstvvSluQpCMY7pqVKqN1L5hK3WO4q5D8/e+CJ/eXO9ndG6WuM9zVlqN1afAY7ppWpbn14+aTfWJj2oIkFWa4a0qO1qXBZrjrBSrNrQ/wzamlujHc9RxH61J9GO4iX7EUGC91rqEu9ac5vS5AvTUxWi8T7EMGu9THHLk3VH75BfD0U+VOXryE7KJVaQuSlJTh3kCl59azuWTrv562GEkdYbg3SJUdHL2PqTRYDPcGOPj4Y4x/aGW5k4cysg1b0xYkqeMM95qr8ilTL5hKg8twrzHn1qXmMtxrKL9+NeweLXWuo3WpHgz3mvFTppLAcK+NKuvWDXWpfvyEag3kK84tF+xHHW2wSzXlyH2A5R+9EkZ3lTrXUJfqrW24hxA2A+cAe2KMJ03x/ELgi8AbgetijJ9KXqWOUHpu3ZtoSI1QZOS+BVgH3DnN808AVwB/lKgmzWD3e86BXz5R6lxH61JztJ1zjzE+wESAT/f8nhjjD4ADKQvTkfIV55YL9qHMYJcaxjn3AZBfswL27S51rnvCSM3U1XAPIawEVgLEGGm1WpXbHB4eTtJOv9q97PTS587f+mDCSnqj7u/voZrUV7C/HX+9rr0SEGPcAGyYfDi+d+/eym22Wi1StNNv8k2fhofvL3fywlPI1txUiz+Xur6/U2lSX8H+ljUyMlLoOKdl+lDplTDu4ChpUpGlkPcAi4FWCGEUuBGYCxBjXB9COB74IfAS4GAI4UrgdTHGX3as6prK79sGcVO5k5evIVt0RtqCJA2stuEeY7ywzfOPAQuSVdRQ7gkjKSW3H+gDpYP9lEUGu6QpOefeQ/m6m2HHw6XONdQlzcRw75Gyo/WjzruEZ/7gjxNXI6luDPcuq/KBpGzjNo5t2PIxSeUY7l1Uem79mOPIPvXFtMVIqjXDvQvyrXfD9ljqXOfWJZVhuHdY+SWOQ2Qb701ai6TmMNw7qGywO1qXVJXh3gHeIUlSrxnuiZWehllzM9nC16ctRlJjGe6J5GtvgJ07Sp3raF1SaoZ7AqVH65Nb80pSaoZ7BfmX1sP920ud62hdUicZ7iWVHq2fsJDs2tvSFiNJhzHcS3CJo6R+Z7jPQn7L1bBr5+xPdPsASV1muBfkEkdJg8Rwb6PKre+chpHUK4b7DEqP1ucvIPvYHWmLkaRZMNyn4UVTSYPMcD9M6e15j55H9rkvpy9Ikkow3A9RdrQ+9PENzHnp8YmrkaTyDPdJTsNIqpPGh3u+6h2QH5j9ie4LI6mPNTrcHa1LqqtGhrsbfkmqu8aFe75iKTA++xMXLyG7aFXyeiSpExoV7k7DSGqKRoR76XuaetFU0oCqfbg7WpfURHN6XUAnGeySmqqWI/f8qkth/77Zn+hFU0k1Ubtwd7QuSTWaljn4+GMlg33IYJdUO7UYuZeehlm+hmzRGekLkqQeG/hw373s9FLnOVqXVGdtwz2EsBk4B9gTYzxpiueHgM8CS4BfAZfEGH+UutDD5Q9/Dzatnf2J7rsuqQGKjNy3AOuAO6d5/mzgxMmvRcAXJv/bMWWD3dG6pKZoe0E1xvgA8MQMhywF7owxjscYHwKODSG8LFWBU9p8+6xPMdglNUmK1TIvB356yOPRye91zsGDxY9dtNhgl9Q4KS6oDk3xvSm3XQwhrARWAsQYabVapV5wd8Hj5m99sFT7/Wx4eLj0n9sgalJ/m9RXsL8df70EbYwCrzjk8QJgbKoDY4wbgA2TD8f37t2b4OWnlm3cRifb75VWq1XLfk2nSf1tUl/B/pY1MjJS6LgU0zLbgHeHEIZCCG8C9scYf56g3ektXjL9c/MXOA0jqfGKLIW8B1gMtEIIo8CNwFyAGON6YDsTyyAfYWIp5KWdKvZZ2UWryOGFd1NyXxhJes7Q+HiJuxKlMT42NuXszaz4q129Nam/Teor2N+yJqdlprrW+QK12VtGkvQ8w12Sashwl6QaMtwlqYYMd0mqIcNdkmrIcJekGjLcJamGDHdJqiHDXZJqyHCXpBrq6d4yvXphSRpwfb23zFCKrxDCP6VqaxC+7G99v5rUV/tb+astp2UkqYYMd0mqoTqE+4b2h9SK/a2vJvUV7G9H9fKCqiSpQ+owcpckHabtPVT7RQjhLOCzQAZsijF+4rDnjwLuBH4H2AdcEGP8SbfrTKVAfz8ALAeeAR4H3htj/O+uF5pAu74ectx5wFeB02KMP+xiiUkV6W8IIQAfYWLJ8I4Y4zu7WmRCBf4uvxL4a+DYyWOuiTFuP6KhARBC2AycA+yJMZ40xfNDTPxZLGHintOXxBh/1IlaBmLkHkLIgM8DZwOvAy4MIbzusMMuA34RY3wNcDtwa3erTKdgf/8ZODXGeDLwNeC27laZRsG+EkJ4MXAF8HB3K0yrSH9DCCcC1wK/F2P8beDKrheaSMH393ogxhjfAPwJcEd3q0xqC3DWDM+fDZw4+bUS+EKnChmIcAd+F3gkxrgrxvh/wFeApYcds5SJn/4wEXZvm/wpOYja9jfG+N0Y468mHz4ELOhyjakUeW8BbmLiB9j/drO4DijS3xXA52OMvwCIMe7pco0pFenvOPCSyf8/BhjrYn1JxRgfAJ6Y4ZClwJ0xxvEY40PAsSGEl3WilkEJ95cDPz3k8ejk96Y8Jsb4DLAfOK4r1aVXpL+Hugz4dkcr6py2fQ0hvAF4RYzxW90srEOKvLevBV4bQvjHEMJDk9Mag6pIfz8CXBxCGAW2A+/rTmk9Mdt/26UNSrhPNQI/fJlPkWMGReG+hBAuBk4FPtnRijpnxr6GEOYwMc22pmsVdVaR93aYiV/bFwMXAptCCMd2uK5OKdLfC4EtMcYFTMxF3zX5vtdR13JqUP4AR4FXHPJ4AUf+6vbcMSGEYSZ+vZvp16N+VqS/hBDeDlwHnBtjfLpLtaXWrq8vBk4C7g8h/AR4E7AthHBq1ypMq+jf5XtjjAdijI8C/8FE2A+iIv29DIgAMcbvA78OtLpSXfcV+redwqCslvkBcGII4dXAz5i46HL46oFtwHuA7wPnAX8XYxzUkXvb/k5OVfwlcNaAz8nO2NcY434O+YceQrgfuGqAV8sU+bv8TSZHsyGEFhPTNLu6WmU6Rfr7P8DbmOjvbzER7o93tcru2QZcHkL4CrAI2B9j/HknXmggRu6Tc+iXA98B/n3iW/FfQwh/EUI4d/KwvwKOCyE8AnwAuKY31VZXsL+fBOYBXw0h/EsIYVuPyq2kYF9ro2B/vwPsCyH8G/Bd4M9jjPt6U3E1Bfu7BlgRQtgB3MPE8sCBHJiFEO5hYoD5myGE0RDCZSGEVSGEVZOHbGfiB/UjwEZgdadq8ROqklRDAzFylyTNjuEuSTVkuEtSDRnuklRDhrsk1ZDhLkk1ZLhLUg0Z7pJUQ/8PdITXk66oQfsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. With closed-form:\n",
    "\n",
    "For linear regression on a model of the form $y=X \\beta$, where $X$ is a matrix with ***full column rank***, the least squares solution,\n",
    "\n",
    "$\\hat{\\beta}=argmin||X \\beta - y||_{2}$\n",
    "\n",
    "is given by\n",
    "\n",
    "$\\hat{\\beta}=(X^{T}X)^{-1}X^{T}y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vector of ones\n",
    "int = np.ones(shape=y.shape[0])[..., None]\n",
    "\n",
    "#and add to feature matrix\n",
    "X = np.concatenate((int, x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate coefficients using closed-form solution\n",
    "coeffs = inv(X.transpose().dot(X)).dot(X.transpose()).dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:       1.01,\n",
      "Theta1:          0.41\n",
      "Approximated function:  1.01 + 0.41 *X\n"
     ]
    }
   ],
   "source": [
    "print('Intercept:       {:0.2f},\\nTheta1:          {:0.2f}'.format(coeffs[0, 0],coeffs[1, 0]))\n",
    "print('Approximated function: ', np.round(coeffs[0, 0], 2), '+', np.round(coeffs[1, 0], 2), '*X' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. With sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = LR(); regressor.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:       1.01,\n",
      "Theta1:          0.41\n",
      "Approximated function:  1.01 + 0.41 *X\n"
     ]
    }
   ],
   "source": [
    "print('Intercept:       {:0.2f},\\nTheta1:          {:0.2f}'.format(regressor.intercept_[0],regressor.coef_[0, 0]))\n",
    "print('Approximated function: ', np.round(regressor.intercept_[0], 2), '+', np.round(regressor.coef_[0, 0], 2), '*X' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. With Implemented gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Gradient</b>\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = 1/m\\sum_{i=1}^{m}(h(\\theta^{(i)} - y^{(i)}).X_j^{(i)}\n",
    "\\end{equation}\n",
    "\n",
    "<b>Gradients</b>\n",
    "\\begin{equation}\n",
    "\\theta_0: = \\theta_{0} -\\alpha . (1/m .\\sum_{i=1}^{m}(h(\\theta^{(i)} - y^{(i)}).X_0^{(i)})\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\theta_1: = \\theta_{1} -\\alpha . (1/m .\\sum_{i=1}^{m}(h(\\theta^{(i)} - y^{(i)}).X_1^{(i)})\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\theta_2: = \\theta_{2} -\\alpha . (1/m .\\sum_{i=1}^{m}(h(\\theta^{(i)} - y^{(i)}).X_2^{(i)})\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta_j: = \\theta_{j} -\\alpha . (1/m .\\sum_{i=1}^{m}(h(\\theta^{(i)} - y^{(i)}).X_0^{(i)})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, learning_rate=0.01, iterations=100):\n",
    "    '''\n",
    "    Parameters:\n",
    "        X     = Matrix of X with added bias units\n",
    "        y     = Vector of Y\n",
    "        theta = Vector of thetas\n",
    "        learning_rate \n",
    "        iterations = no of iterations\n",
    "    \n",
    "    Returns:\n",
    "        np.array - (Returns the final theta vector and array of cost history over no of iterations)\n",
    "    '''\n",
    "    m = len(y)\n",
    "    for it in range(iterations):\n",
    "        \n",
    "        prediction = np.dot(X,theta)\n",
    "        \n",
    "        theta = theta -(1/m)*learning_rate*( X.T.dot((prediction - y)))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta0:          1.01,\n",
      "Theta1:          0.41\n",
      "Approximated function:  1.01 + 0.41 *X\n"
     ]
    }
   ],
   "source": [
    "lr =0.01\n",
    "n_iter = 100000\n",
    "\n",
    "theta = np.random.randn(2,1)\n",
    "\n",
    "theta = gradient_descent(X, y, theta, lr, n_iter)\n",
    "\n",
    "print('Theta0:          {:0.2f},\\nTheta1:          {:0.2f}'.format(theta[0,0], theta[1,0]))\n",
    "print('Approximated function: ', np.round(theta[0,0], 2), '+', np.round(theta[1,0], 2), '*X' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. With Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(np.random.randn(), name = \"W\")\n",
    "b = tf.Variable(np.random.randn(), name = \"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "training_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0919 02:02:17.988932 11448 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "y_pred = tf.add(tf.multiply(X, W), b)\n",
    "\n",
    "# Mean Squared Error Cost Function\n",
    "cost = tf.reduce_sum(tf.pow(y_pred-Y, 2)) / (2 * n)\n",
    "\n",
    "# Gradient Descent Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 : cost = 0.2724661 W = 0.03711432 b = 0.47051316\n",
      "Epoch 100 : cost = 0.076749 W = 0.1846485 b = 0.74058753\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: \n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        for (_x, _y) in zip(x, y):\n",
    "            sess.run(optimizer, feed_dict = {X : _x, Y : _y})\n",
    "          \n",
    "        # Displaying the result after every 50 epochs\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            # Calculating the cost a every epoch\n",
    "            c = sess.run(cost, feed_dict = {X : x, Y : y})\n",
    "            print(\"Epoch\", (epoch + 1), \": cost =\", c, \"W =\", sess.run(W), \"b =\", sess.run(b))\n",
    "\n",
    "    weight = sess.run(W)\n",
    "    bias = sess.run(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

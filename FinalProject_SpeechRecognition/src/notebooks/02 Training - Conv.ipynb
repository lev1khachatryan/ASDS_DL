{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# sys.path.append(\"../libs\")\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "from libs import input_data\n",
    "from libs import models\n",
    "from libs import trainer\n",
    "from libs import freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags=tf.app.flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags=tf.app.flags\n",
    "#Important Directories\n",
    "flags.DEFINE_string('data_dir','..\\\\data\\\\raw','Train Data Folder')\n",
    "flags.DEFINE_string('summaries_dir','..\\\\summaries','Summaries Folder')\n",
    "flags.DEFINE_string('train_dir','..\\\\logs&checkpoint','Directory to write event logs and checkpoint')\n",
    "flags.DEFINE_string('models_dir','..\\\\models','Models Folder')\n",
    "#Task Specific Parameters\n",
    "flags.DEFINE_string('wanted_words','yes,no,up,down,left,right,on,off,stop,go','Wanted Words')\n",
    "flags.DEFINE_float('validation_percentage',10,'Validation Percentage')\n",
    "flags.DEFINE_float('testing_percentage',10,'Testing Percentage')\n",
    "flags.DEFINE_integer('sample_rate',16000,'Sample Rate')\n",
    "flags.DEFINE_integer('clip_duration_ms',1000,'Clip Duration in ms')\n",
    "flags.DEFINE_float('window_size_ms',30,'How long each spectogram timeslice is')\n",
    "flags.DEFINE_float('window_stride_ms',10.0,'How far to move in time between frequency windows.')\n",
    "flags.DEFINE_integer('dct_coefficient_count',40,'How many bins to use for the MFCC fingerprint')\n",
    "flags.DEFINE_float('time_shift_ms',100.0,'Range to randomly shift the training audio by in time.')\n",
    "\n",
    "FLAGS=flags.FLAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_architecture='conv'\n",
    "start_checkpoint=None\n",
    "logging_interval=1\n",
    "eval_step_interval=2000\n",
    "save_step_interval=1\n",
    "silence_percentage=10.0\n",
    "unknown_percentage=10.0\n",
    "background_frequency=0.8\n",
    "background_volume=0.1\n",
    "learning_rate='0.001,0.0001' #Always seperated by comma, trains with each of the learning rate for the given number of iterations\n",
    "train_steps='15000,300' #Declare  the training steps for which the learning rates will be used\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the get_train_data() get_val_data() and get_test_data() Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_args = FLAGS([sys.argv[0]] + [flag for flag in sys.argv if flag.startswith(\"--\")])\n",
    "assert(remaining_args == [sys.argv[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=os.path.join(FLAGS.data_dir,'train','audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_settings = models.prepare_model_settings(\n",
    "      len(input_data.prepare_words_list(FLAGS.wanted_words.split(','))),\n",
    "      FLAGS.sample_rate, FLAGS.clip_duration_ms, FLAGS.window_size_ms,\n",
    "      FLAGS.window_stride_ms, FLAGS.dct_coefficient_count)\n",
    "audio_processor = input_data.AudioProcessor(\n",
    "      train_dir, silence_percentage, unknown_percentage,\n",
    "      FLAGS.wanted_words.split(','), FLAGS.validation_percentage,\n",
    "      FLAGS.testing_percentage, model_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(args):\n",
    "    sess=args\n",
    "    time_shift_samples = int((FLAGS.time_shift_ms * FLAGS.sample_rate) / 1000)\n",
    "    train_fingerprints, train_ground_truth = audio_processor.get_data(\n",
    "        batch_size, 0, model_settings,background_frequency,\n",
    "        background_volume, time_shift_samples, 'training', sess)\n",
    "    return train_fingerprints,train_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_data(args):\n",
    "    '''\n",
    "    Input: (sess,offset)\n",
    "    '''\n",
    "    sess,i=args\n",
    "    validation_fingerprints, validation_ground_truth = (\n",
    "            audio_processor.get_data(batch_size, i, model_settings, 0.0,\n",
    "                                     0.0, 0, 'validation', sess))\n",
    "    return validation_fingerprints,validation_ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    sess=tf.InteractiveSession()\n",
    "    # Placeholders\n",
    "    fingerprint_size = model_settings['fingerprint_size']\n",
    "    label_count = model_settings['label_count']\n",
    "    fingerprint_input = tf.placeholder(\n",
    "      tf.float32, [None, fingerprint_size], name='fingerprint_input')\n",
    "    ground_truth_input = tf.placeholder(\n",
    "      tf.float32, [None, label_count], name='groundtruth_input')\n",
    "    set_size = audio_processor.set_size('validation')\n",
    "    label_count = model_settings['label_count']\n",
    "    # Create Model\n",
    "    \n",
    "    logits, dropout_prob = models.create_model(\n",
    "      fingerprint_input,\n",
    "      model_settings,\n",
    "      model_architecture,\n",
    "      is_training=True)\n",
    "    #Start Training\n",
    "    extra_args=(dropout_prob,label_count,batch_size,set_size)\n",
    "    trainer.train(sess,logits,fingerprint_input,ground_truth_input,get_train_data,\n",
    "                  get_val_data,train_steps,learning_rate,eval_step_interval, logging_interval=logging_interval,\n",
    "                  start_checkpoint=start_checkpoint,checkpoint_interval=save_step_interval,\n",
    "                  model_name=model_architecture,train_dir=FLAGS.train_dir,\n",
    "                  summaries_dir=FLAGS.summaries_dir,args=extra_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.app.run(main=main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path=os.path.join(FLAGS.models_dir,model_architecture,'%s.pb'%os.path.basename(save_checkpoint))\n",
    "freeze.freeze_graph(FLAGS,model_architecture,save_checkpoint,save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

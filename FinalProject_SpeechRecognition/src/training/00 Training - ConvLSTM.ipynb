{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0123 14:57:38.772894  7024 deprecation_wrapper.py:119] From ..\\libs\\trainer.py:13: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W0123 14:57:38.779038  7024 deprecation_wrapper.py:119] From ..\\libs\\trainer.py:13: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# sys.path.append(\"../libs\")\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "from libs import input_data\n",
    "from libs import models\n",
    "from libs import trainer\n",
    "from libs import freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags=tf.app.flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags=tf.app.flags\n",
    "#Important Directories\n",
    "flags.DEFINE_string('data_dir','..\\\\..\\\\_inputs\\\\raw','Train Data Folder')\n",
    "flags.DEFINE_string('summaries_dir','..\\\\..\\\\summaries','Summaries Folder')\n",
    "flags.DEFINE_string('train_dir','..\\\\..\\\\logs&checkpoint','Directory to write event logs and checkpoint')\n",
    "flags.DEFINE_string('models_dir','..\\\\..\\\\models','Models Folder')\n",
    "#Task Specific Parameters\n",
    "flags.DEFINE_string('wanted_words','yes,no,up,down,left,right,on,off,stop,go','Wanted Words')\n",
    "flags.DEFINE_float('validation_percentage',10,'Validation Percentage')\n",
    "flags.DEFINE_float('testing_percentage',10,'Testing Percentage')\n",
    "flags.DEFINE_integer('sample_rate',16000,'Sample Rate')\n",
    "flags.DEFINE_integer('clip_duration_ms',1000,'Clip Duration in ms')\n",
    "flags.DEFINE_float('window_size_ms',30,'How long each spectogram timeslice is')\n",
    "flags.DEFINE_float('window_stride_ms',10.0,'How far to move in time between frequency windows.')\n",
    "flags.DEFINE_integer('dct_coefficient_count',40,'How many bins to use for the MFCC fingerprint')\n",
    "flags.DEFINE_float('time_shift_ms',200.0,'Range to randomly shift the training audio by in time.')\n",
    "\n",
    "FLAGS=flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_architecture='convlstm'\n",
    "start_checkpoint=None\n",
    "logging_interval=10\n",
    "eval_step_interval=500\n",
    "save_step_interval=2000\n",
    "silence_percentage=10.0\n",
    "unknown_percentage=10.0\n",
    "background_frequency=0.8\n",
    "background_volume=0.3\n",
    "learning_rate='0.0005,0.0001,0.00002,0.0001,0.00002' #Always seperated by comma, trains with each of the learning rate for the given number of iterations\n",
    "train_steps='10000,10000,2000,27000,5000' #Declare  the training steps for which the learning rates will be used\n",
    "batch_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_args = FLAGS([sys.argv[0]] + [flag for flag in sys.argv if flag.startswith(\"--\")])\n",
    "assert(remaining_args == [sys.argv[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=os.path.join(FLAGS.data_dir,'train','audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\..\\_inputs\\raw\\train\\audio\\*\\*.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0123 14:57:41.995376  7024 deprecation_wrapper.py:119] From ..\\libs\\input_data.py:304: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0123 14:57:42.027674  7024 deprecation_wrapper.py:119] From ..\\libs\\input_data.py:305: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\..\\_inputs\\raw\\train\\audio\\_background_noise_\\doing_the_dishes.wav\n",
      "..\\..\\_inputs\\raw\\train\\audio\\_background_noise_\\dude_miaowing.wav\n",
      "..\\..\\_inputs\\raw\\train\\audio\\_background_noise_\\exercise_bike.wav\n",
      "..\\..\\_inputs\\raw\\train\\audio\\_background_noise_\\pink_noise.wav\n",
      "..\\..\\_inputs\\raw\\train\\audio\\_background_noise_\\running_tap.wav\n",
      "..\\..\\_inputs\\raw\\train\\audio\\_background_noise_\\white_noise.wav\n",
      "Tensor(\"AudioSpectrogram:0\", shape=(?, 98, 257), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model_settings = models.prepare_model_settings(\n",
    "      len(input_data.prepare_words_list(FLAGS.wanted_words.split(','))),\n",
    "      FLAGS.sample_rate, FLAGS.clip_duration_ms, FLAGS.window_size_ms,\n",
    "      FLAGS.window_stride_ms, FLAGS.dct_coefficient_count)\n",
    "audio_processor = input_data.AudioProcessor(\n",
    "      train_dir, silence_percentage, unknown_percentage,\n",
    "      FLAGS.wanted_words.split(','), FLAGS.validation_percentage,\n",
    "      FLAGS.testing_percentage, model_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(args):\n",
    "    sess=args\n",
    "    time_shift_samples = int((FLAGS.time_shift_ms * FLAGS.sample_rate) / 1000)\n",
    "    train_fingerprints, train_ground_truth = audio_processor.get_data(\n",
    "        batch_size, 0, model_settings,background_frequency,\n",
    "        background_volume, time_shift_samples, 'training', sess)\n",
    "    return train_fingerprints,train_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_data(args):\n",
    "    '''\n",
    "    Input: (sess,offset)\n",
    "    '''\n",
    "    sess,i=args\n",
    "    validation_fingerprints, validation_ground_truth = (\n",
    "            audio_processor.get_data(batch_size, i, model_settings, 0.0,\n",
    "                                     0.0, 0, 'validation', sess))\n",
    "    return validation_fingerprints,validation_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    sess=tf.InteractiveSession()\n",
    "    # Placeholders\n",
    "    fingerprint_size = model_settings['fingerprint_size']\n",
    "    label_count = model_settings['label_count']\n",
    "    fingerprint_input = tf.placeholder(\n",
    "      tf.float32, [None, fingerprint_size], name='fingerprint_input')\n",
    "    ground_truth_input = tf.placeholder(\n",
    "      tf.float32, [None, label_count], name='groundtruth_input')\n",
    "    set_size = audio_processor.set_size('validation')\n",
    "    label_count = model_settings['label_count']\n",
    "    # Create Model\n",
    "    \n",
    "    logits, dropout_prob = models.create_model( \n",
    "      fingerprint_input,\n",
    "      model_settings,\n",
    "      model_architecture,\n",
    "      is_training=True)\n",
    "    #Start Training\n",
    "    extra_args=(dropout_prob,label_count,batch_size,set_size)\n",
    "    trainer.train(sess,logits,fingerprint_input,ground_truth_input,get_train_data,\n",
    "                  get_val_data,train_steps,learning_rate,eval_step_interval, logging_interval=logging_interval,\n",
    "                  start_checkpoint=start_checkpoint,checkpoint_interval=save_step_interval,\n",
    "                  model_name=model_architecture,train_dir=FLAGS.train_dir,\n",
    "                  summaries_dir=FLAGS.summaries_dir,args=extra_args,dropout=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf.app.run(main=main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_checkpoint='..\\\\..\\\\logs&checkpoint\\\\convlstm\\\\ckpt-1000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# save_path=os.path.join(FLAGS.models_dir,model_architecture,'%s.pb'%os.path.basename(save_checkpoint))\n",
    "# freeze.freeze_graph(FLAGS,model_architecture,save_checkpoint,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path=os.path.join(FLAGS.models_dir,model_architecture,'%s-batched.pb'%os.path.basename(save_checkpoint))\n",
    "# freeze.freeze_graph(FLAGS,model_architecture,save_checkpoint,save_path,batched=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

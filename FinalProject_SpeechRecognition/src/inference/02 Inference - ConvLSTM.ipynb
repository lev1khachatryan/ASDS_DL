{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sys.path.append(\"../libs\")\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "from libs import label_wav\n",
    "from libs import input_data\n",
    "from libs import models\n",
    "from tensorflow.python.platform import gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags=tf.app.flags\n",
    "#Important Directories\n",
    "flags.DEFINE_string('data_dir','..\\\\..\\\\_inputs\\\\raw','Train Data Folder')\n",
    "flags.DEFINE_string('summaries_dir','..\\\\..\\\\summaries','Summaries Folder')\n",
    "flags.DEFINE_string('results_dir','..\\\\..\\\\results','Directory to write event logs and checkpoint')\n",
    "flags.DEFINE_string('models_dir','..\\\\..\\\\models','Models Folder')\n",
    "flags.DEFINE_string('predictions_dir','..\\\\..\\\\predictions','Predictions Directory')\n",
    "flags.DEFINE_string('wanted_words','yes,no,up,down,left,right,on,off,stop,go','Wanted Words')\n",
    "FLAGS=flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers = [op.name for op in graph.get_operations()]\n",
    "# for layer in layers:\n",
    "#     print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers = [op.name for op in graph.get_operations()]\n",
    "# for layer in layers:\n",
    "#     print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction_onehot = model.test(data = x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data):\n",
    "    # Know your output node name\n",
    "    output_tensor = graph.get_tensor_by_name(\"labels_softmax:0\")\n",
    "    output = sess.run(output_tensor, feed_dict = {input: data})\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_tensor_by_name(\"labels_softmax:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_tensor_by_name(\"fingerprint_input:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(object):\n",
    "\n",
    "    def __init__(self, model_filepath):\n",
    "\n",
    "        # The file path of model\n",
    "        self.model_filepath = model_filepath\n",
    "        # Initialize the model\n",
    "        self.load_graph(model_filepath = self.model_filepath)\n",
    "\n",
    "    def load_graph(self, model_filepath):\n",
    "        '''\n",
    "        Lode trained model.\n",
    "        '''\n",
    "        print('Loading model...')\n",
    "        self.graph = tf.Graph()\n",
    "        self.sess = tf.InteractiveSession(graph = self.graph)\n",
    "\n",
    "        with tf.gfile.GFile(model_filepath, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "\n",
    "        print('Check out the input placeholders:')\n",
    "        nodes = [n.name + ' => ' +  n.op for n in graph_def.node if n.op in ('Placeholder')]\n",
    "        for node in nodes:\n",
    "            print(node)\n",
    "\n",
    "        # Define input tensor\n",
    "        self.input = tf.placeholder(np.float32, shape = [None, 1960], name='input')\n",
    "#         self.dropout_rate = tf.placeholder(tf.float32, shape = [], name = 'dropout_rate')\n",
    "\n",
    "        tf.import_graph_def(graph_def, {'input': self.input, 'dropout_rate': self.dropout_rate})\n",
    "\n",
    "        print('Model loading complete!')\n",
    "\n",
    "        '''\n",
    "        # Get layer names\n",
    "        layers = [op.name for op in self.graph.get_operations()]\n",
    "        for layer in layers:\n",
    "            print(layer)\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        # Check out the weights of the nodes\n",
    "        weight_nodes = [n for n in graph_def.node if n.op == 'Const']\n",
    "        for n in weight_nodes:\n",
    "            print(\"Name of the node - %s\" % n.name)\n",
    "            print(\"Value - \" )\n",
    "            print(tensor_util.MakeNdarray(n.attr['value'].tensor))\n",
    "        '''\n",
    "\n",
    "    def test(self, data):\n",
    "\n",
    "        # Know your output node name\n",
    "        output_tensor = self.graph.get_tensor_by_name(\"labels_softmax:0\")\n",
    "        output = self.sess.run(output_tensor, feed_dict = {self.input: data, self.dropout_rate: 0})\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flags.DEFINE_float('time_shift_ms',100.0,'Range to randomly shift the training audio by in time.')\n",
    "time_shift_ms = 100.0\n",
    "sample_rate = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(args):\n",
    "    sess=args\n",
    "    time_shift_samples = int((time_shift_ms * sample_rate) / 1000)\n",
    "    train_data, train_ground_truth = audio_processor.get_data(\n",
    "        batch_size, 0, model_settings, background_frequency,\n",
    "        background_volume, time_shift_samples, 'training', sess)\n",
    "    return train_data, train_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_ground_truth = get_train_data(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Load CIFAR10 dataset\n",
    "cifar10 = CIFAR10()\n",
    "x_test = cifar10.x_test\n",
    "y_test = cifar10.y_test\n",
    "y_test_onehot = cifar10.y_test_onehot\n",
    "num_classes = cifar10.num_classes\n",
    "input_size = cifar10.input_size\n",
    "\n",
    "# Test 500 samples\n",
    "x_test = x_test[0:500]\n",
    "y_test = y_test[0:500]\n",
    "\n",
    "model = CNN(model_filepath = model_path)\n",
    "\n",
    "test_prediction_onehot = model.test(data = x_test)\n",
    "test_prediction = np.argmax(test_prediction_onehot, axis = 1).reshape((-1,1))\n",
    "test_accuracy = model_accuracy(label = y_test, prediction = test_prediction)\n",
    "\n",
    "print('Test Accuracy: %f' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags=tf.app.flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags=tf.app.flags\n",
    "#Important Directories\n",
    "flags.DEFINE_string('data_dir','..\\\\..\\\\_inputs\\\\raw','Train Data Folder')\n",
    "flags.DEFINE_string('summaries_dir','..\\\\..\\\\summaries','Summaries Folder')\n",
    "flags.DEFINE_string('train_dir','..\\\\..\\\\logs&checkpoint','Directory to write event logs and checkpoint')\n",
    "flags.DEFINE_string('models_dir','..\\\\..\\\\models','Models Folder')\n",
    "#Task Specific Parameters\n",
    "flags.DEFINE_string('wanted_words','bed,bird,cat,dog,down,eight,five,four,go,happy,house,left,marvin,nine,no,off,on,one,right,seven,sheila,six,stop,three,tree,two,up,wow,yes,zero','Wanted Words')\n",
    "flags.DEFINE_float('validation_percentage',10,'Validation Percentage')\n",
    "flags.DEFINE_float('testing_percentage',10,'Testing Percentage')\n",
    "flags.DEFINE_integer('sample_rate',16000,'Sample Rate')\n",
    "flags.DEFINE_integer('clip_duration_ms',1000,'Clip Duration in ms')\n",
    "flags.DEFINE_float('window_size_ms',30,'How long each spectogram timeslice is')\n",
    "flags.DEFINE_float('window_stride_ms',10.0,'How far to move in time between frequency windows.')\n",
    "flags.DEFINE_integer('dct_coefficient_count',40,'How many bins to use for the MFCC')\n",
    "flags.DEFINE_float('time_shift_ms',100.0,'Range to randomly shift the training audio by in time.')\n",
    "\n",
    "FLAGS=flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_architecture='conv'\n",
    "start_checkpoint=None\n",
    "logging_interval=1\n",
    "eval_step_interval=1000\n",
    "save_step_interval=1\n",
    "silence_percentage=10.0\n",
    "unknown_percentage=10.0\n",
    "background_frequency=0.8\n",
    "background_volume=0.1\n",
    "learning_rate='0.001,0.0001' #Always seperated by comma, trains with each of the learning rate for the given number of iterations\n",
    "train_steps='1000,1000' #Declare  the training steps for which the learning rates will be used\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(args):\n",
    "    sess=args\n",
    "    time_shift_samples = int((FLAGS.time_shift_ms * FLAGS.sample_rate) / 1000)\n",
    "    train_data, train_ground_truth = audio_processor.get_data(\n",
    "        batch_size, 0, model_settings, background_frequency,\n",
    "        background_volume, time_shift_samples, 'training', sess)\n",
    "    return train_data, train_ground_truth\n",
    "\n",
    "def get_val_data(args):\n",
    "    '''\n",
    "    Input: (sess,offset)\n",
    "    '''\n",
    "    sess,i=args\n",
    "    validation_data, validation_ground_truth = (\n",
    "        audio_processor.get_data(batch_size, i, model_settings, 0.0,\n",
    "                                     0.0, 0, 'validation', sess))\n",
    "    return validation_data,validation_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_args = FLAGS([sys.argv[0]] + [flag for flag in sys.argv if flag.startswith(\"--\")])\n",
    "assert(remaining_args == [sys.argv[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=os.path.join(FLAGS.data_dir,'train','audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORD_LIST = [x[0].rsplit('\\\\', 2)[-1] for x in os.walk(train_dir)]\n",
    "# ','.join(WORD_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_settings = models.prepare_model_settings(\n",
    "#       len(input_data.prepare_words_list(FLAGS.wanted_words.split(','))),\n",
    "#       FLAGS.sample_rate, FLAGS.clip_duration_ms, FLAGS.window_size_ms,\n",
    "#       FLAGS.window_stride_ms, FLAGS.dct_coefficient_count)\n",
    "# audio_processor = input_data.AudioProcessor(\n",
    "#       train_dir, silence_percentage, unknown_percentage,\n",
    "#       FLAGS.wanted_words.split(','), FLAGS.validation_percentage,\n",
    "#       FLAGS.testing_percentage, model_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0123 14:47:01.665774 19620 deprecation_wrapper.py:119] From ..\\libs\\trainer.py:13: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W0123 14:47:01.671472 19620 deprecation_wrapper.py:119] From ..\\libs\\trainer.py:13: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# sys.path.append(\"../libs\")\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "from libs import input_data\n",
    "from libs import models\n",
    "from libs import trainer\n",
    "from libs import freeze\n",
    "import hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags=tf.app.flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags=tf.app.flags\n",
    "#Important Directories\n",
    "flags.DEFINE_string('data_dir','..\\\\..\\\\_inputs\\\\raw','Train Data Folder')\n",
    "flags.DEFINE_string('summaries_dir','..\\\\..\\\\summaries','Summaries Folder')\n",
    "flags.DEFINE_string('train_dir','..\\\\..\\\\logs&checkpoint','Directory to write event logs and checkpoint')\n",
    "flags.DEFINE_string('models_dir','..\\\\..\\\\models','Models Folder')\n",
    "#Task Specific Parameters\n",
    "flags.DEFINE_string('wanted_words','yes,no,up,down,left,right,on,off,stop,go','Wanted Words')\n",
    "flags.DEFINE_float('validation_percentage',10,'Validation Percentage')\n",
    "flags.DEFINE_float('testing_percentage',10,'Testing Percentage')\n",
    "flags.DEFINE_integer('sample_rate',16000,'Sample Rate')\n",
    "flags.DEFINE_integer('clip_duration_ms',1000,'Clip Duration in ms')\n",
    "flags.DEFINE_float('window_size_ms',30,'How long each spectogram timeslice is')\n",
    "flags.DEFINE_float('window_stride_ms',10.0,'How far to move in time between frequency windows.')\n",
    "flags.DEFINE_integer('dct_coefficient_count',40,'How many bins to use for the MFCC fingerprint')\n",
    "flags.DEFINE_float('time_shift_ms',100.0,'Range to randomly shift the training audio by in time.')\n",
    "\n",
    "FLAGS=flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_architecture='convlstm'\n",
    "start_checkpoint=None\n",
    "logging_interval=10\n",
    "eval_step_interval=1000\n",
    "save_step_interval=100000\n",
    "silence_percentage=10.0\n",
    "unknown_percentage=10.0\n",
    "background_frequency=0.8\n",
    "background_volume=0.1\n",
    "train_steps='3500' #Declare  the training steps for which the learning rates will be used\n",
    "learning_rate='0.0001'\n",
    "batch_size=256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model to be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resCONVLSTM(inputs, model_settings, is_training, name='',conv_lstm_filter_size=4):\n",
    "    \"\"\"Creates a Residual ConvLSTM as in https://arxiv.org/abs/1607.06450.\n",
    "        1-D Conv on feature, unidirectional rnn\n",
    "        \n",
    "    \"\"\"\n",
    "    with(tf.variable_scope('resCONVLSTM_%s' % name)):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        input_frequency_size = model_settings['dct_coefficient_count']\n",
    "        input_time_size = model_settings['spectrogram_length']\n",
    "        input_shape = [input_frequency_size, 1]\n",
    "        conv1 = tf.contrib.rnn.ConvLSTMCell(1, input_shape, 1, [conv_lstm_filter_size], name='conv1')\n",
    "        conv2 = tf.contrib.rnn.ConvLSTMCell(1, input_shape, 1, [conv_lstm_filter_size], name='conv2')\n",
    "        # First ConvLSTM\n",
    "        initial_conv1 = conv1.zero_state(batch_size, dtype=tf.float32)\n",
    "        initial_conv2 = conv2.zero_state(batch_size, dtype=tf.float32)\n",
    "        conv1_o, _ = tf.nn.dynamic_rnn(conv1, inputs, initial_state=initial_conv1)\n",
    "        bn1 = tf.layers.batch_normalization(inputs, axis=2, training=is_training)\n",
    "        bn1_relu = tf.nn.relu(bn1)\n",
    "        conv2_o, _ = tf.nn.dynamic_rnn(conv2, bn1_relu, initial_state=initial_conv2)\n",
    "        bn2 = tf.layers.batch_normalization(conv2_o, axis=2, training=is_training)\n",
    "        residual = tf.add(bn2, inputs)\n",
    "        output_relu = tf.nn.relu(residual)\n",
    "        return output_relu\n",
    "\n",
    "\n",
    "def create_multilayer_convlstm_model(fingerprint_input, model_settings, is_training,conv_lstm_filter_size=4,lstm_size=256,dense_size=256):\n",
    "    \"\"\"\n",
    "        Creates a Multilayer ConvLSTM Model Followed by a linear layer and softmax activation function\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    if is_training:\n",
    "        dropout_prob = tf.placeholder(tf.float32, name='dropout_prob')\n",
    "    batch_size = tf.shape(fingerprint_input)[0]\n",
    "    input_frequency_size = model_settings['dct_coefficient_count']\n",
    "    input_time_size = model_settings['spectrogram_length']\n",
    "    fingerprint_4d = tf.reshape(fingerprint_input,\n",
    "                                [-1, input_time_size, input_frequency_size, 1])\n",
    "\n",
    "    # Layer1 resCONVLSTMs\n",
    "    resCONVLSTM1 = resCONVLSTM(fingerprint_4d, model_settings, is_training, '1',conv_lstm_filter_size)\n",
    "    resCONVLSTM2 = resCONVLSTM(resCONVLSTM1, model_settings, is_training, '2',conv_lstm_filter_size)\n",
    "    resCONVLSTM3 = resCONVLSTM(resCONVLSTM2, model_settings, is_training, '3',conv_lstm_filter_size)\n",
    "    resCONVLSTM4= resCONVLSTM(resCONVLSTM3,model_settings,is_training,'4',conv_lstm_filter_size)\n",
    "    resCONVLSTM4=tf.reshape(resCONVLSTM4,[-1, input_time_size, input_frequency_size])\n",
    "    with tf.variable_scope('lstm1'):\n",
    "        lstm_cell1=tf.contrib.rnn.LSTMCell(num_units=lstm_size,num_proj=input_frequency_size)\n",
    "        initial_lstm1=lstm_cell1.zero_state(batch_size,dtype=tf.float32)\n",
    "        lstm1_o,_=tf.nn.dynamic_rnn(lstm_cell1,resCONVLSTM4,initial_state=initial_lstm1)\n",
    "        lstm1_o=tf.reshape(lstm1_o,[-1, input_time_size, input_frequency_size,1 ])\n",
    "        nin1_o=tf.layers.conv2d(lstm1_o,1,[1,1],name='nin1')\n",
    "        bn1=tf.layers.batch_normalization(nin1_o, axis=2, training=is_training)\n",
    "        bn1=tf.reshape(bn1,[-1,input_time_size,input_frequency_size])\n",
    "    with tf.variable_scope('lstm2'):\n",
    "        lstm_cell2=tf.contrib.rnn.LSTMCell(num_units=lstm_size,num_proj=input_frequency_size)\n",
    "        initial_lstm2=lstm_cell1.zero_state(batch_size,dtype=tf.float32)\n",
    "        lstm2_o, _ = tf.nn.dynamic_rnn(lstm_cell2, bn1, initial_state=initial_lstm2)\n",
    "        lstm2_o = tf.reshape(lstm2_o, [-1, input_time_size, input_frequency_size, 1])\n",
    "        nin2_o = tf.layers.conv2d(lstm2_o, 1, [1, 1], name='nin1')\n",
    "        bn2 = tf.layers.batch_normalization(nin2_o, axis=2, training=is_training)\n",
    "        bn2=tf.reshape(bn2,[-1,input_time_size,input_frequency_size])\n",
    "\n",
    "    # LSTM Layer Final\n",
    "    with tf.variable_scope('lstm3'):\n",
    "        lstm_cell3=tf.contrib.rnn.LSTMCell(num_units=lstm_size,num_proj=input_frequency_size)\n",
    "        initial_lstm3=lstm_cell1.zero_state(batch_size,dtype=tf.float32)\n",
    "        lstm3_o, _ = tf.nn.dynamic_rnn(lstm_cell3, bn2, initial_state=initial_lstm3)\n",
    "        lstm3_o = tf.reshape(lstm3_o, [-1, input_time_size, input_frequency_size, 1])\n",
    "\n",
    "\n",
    "    # Final FC for classification\n",
    "    reshaped_layer = tf.reshape(lstm3_o,\n",
    "                                 [-1, input_time_size * input_frequency_size])\n",
    "\n",
    "    # Dropout\n",
    "    if is_training:\n",
    "        reshaped_layer = tf.nn.dropout(reshaped_layer, keep_prob=dropout_prob)\n",
    "\n",
    "\n",
    "    prefinal_dense=tf.nn.relu(tf.layers.dense(reshaped_layer,dense_size))\n",
    "\n",
    "    if is_training:\n",
    "        prefinal_dense=tf.nn.dropout(prefinal_dense,keep_prob=dropout_prob)\n",
    "    # Final Layer\n",
    "\n",
    "    label_count = model_settings['label_count']\n",
    "\n",
    "    final_fc_weights = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            [dense_size, label_count], stddev=0.01))\n",
    "    final_fc_bias = tf.Variable(tf.zeros([label_count]))\n",
    "    final_fc = tf.matmul(prefinal_dense, final_fc_weights) + final_fc_bias\n",
    "    if is_training:\n",
    "        return final_fc, dropout_prob\n",
    "    else:\n",
    "        return final_fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(args):\n",
    "    conv_lstm_filter_size=int(args['conv_lstm_filter_size'])\n",
    "    lstm_size=int(args['lstm_size'])\n",
    "    dense_size=int(args['dense_size'])\n",
    "    dropout=args['dropout']\n",
    "    \n",
    "    print('Eval Start')\n",
    "    print(conv_lstm_filter_size,lstm_size,dense_size,dropout)\n",
    "    tf.reset_default_graph()\n",
    "    train_dir=os.path.join(FLAGS.data_dir,'train','audio')\n",
    "    model_settings = models.prepare_model_settings(\n",
    "      len(input_data.prepare_words_list(FLAGS.wanted_words.split(','))),\n",
    "      FLAGS.sample_rate, FLAGS.clip_duration_ms, FLAGS.window_size_ms,\n",
    "      FLAGS.window_stride_ms, FLAGS.dct_coefficient_count)\n",
    "    audio_processor = input_data.AudioProcessor(\n",
    "      train_dir, silence_percentage, unknown_percentage,\n",
    "      FLAGS.wanted_words.split(','), FLAGS.validation_percentage,\n",
    "      FLAGS.testing_percentage, model_settings)\n",
    "    \n",
    "    def get_train_data(args):\n",
    "        sess=args\n",
    "        time_shift_samples = int((FLAGS.time_shift_ms * FLAGS.sample_rate) / 1000)\n",
    "        train_fingerprints, train_ground_truth = audio_processor.get_data(\n",
    "            batch_size, 0, model_settings,background_frequency,\n",
    "            background_volume, time_shift_samples, 'training', sess)\n",
    "        return train_fingerprints,train_ground_truth\n",
    "    \n",
    "    def get_val_data(args):\n",
    "        '''\n",
    "        Input: (sess,offset)\n",
    "        '''\n",
    "        sess,i=args\n",
    "        validation_fingerprints, validation_ground_truth = (\n",
    "                audio_processor.get_data(batch_size, i, model_settings, 0.0,\n",
    "                                         0.0, 0, 'validation', sess))\n",
    "        return validation_fingerprints,validation_ground_truth\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # Placeholders\n",
    "        fingerprint_size = model_settings['fingerprint_size']\n",
    "        label_count = model_settings['label_count']\n",
    "        fingerprint_input = tf.placeholder(\n",
    "          tf.float32, [None, fingerprint_size], name='fingerprint_input')\n",
    "        ground_truth_input = tf.placeholder(\n",
    "          tf.float32, [None, label_count], name='groundtruth_input')\n",
    "        set_size = audio_processor.set_size('validation')\n",
    "        label_count = model_settings['label_count']\n",
    "        # Create Model\n",
    "\n",
    "        logits, dropout_prob = create_multilayer_convlstm_model(\n",
    "          fingerprint_input,\n",
    "          model_settings,\n",
    "          True,\n",
    "          conv_lstm_filter_size,\n",
    "          lstm_size,\n",
    "          dense_size)\n",
    "        #Start Training\n",
    "        extra_args=(dropout_prob,label_count,batch_size,set_size)\n",
    "        val_acc=trainer.train(sess,logits,fingerprint_input,ground_truth_input,get_train_data,\n",
    "                      get_val_data,train_steps,learning_rate,eval_step_interval, logging_interval=logging_interval,\n",
    "                      start_checkpoint=None,checkpoint_interval=None,\n",
    "                      model_name=model_architecture,train_dir=None,\n",
    "                      summaries_dir=None,dropout=dropout,args=extra_args)\n",
    "    return 1-val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "        'conv_lstm_filter_size': hyperopt.hp.uniform('conv_lstm_filter_size', 4,6),\n",
    "        'lstm_size': hyperopt.hp.uniform('lstm_size', 128,256),\n",
    "        'dense_size': hyperopt.hp.uniform('dense_size', 128,256),\n",
    "        'dropout':hyperopt.hp.uniform('dropout',0.3,1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_args = FLAGS([sys.argv[0]] + [flag for flag in sys.argv if flag.startswith(\"--\")])\n",
    "assert(remaining_args == [sys.argv[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Start                                                                                                             \n",
      "4                                                                                                                      \n",
      "226                                                                                                                    \n",
      "207                                                                                                                    \n",
      "0.8161283892926225                                                                                                     \n",
      "..\\..\\_inputs\\raw\\train\\audio\\*\\*.wav                                                                                  \n",
      "  0%|                                                                            | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0123 14:47:05.552361 19620 deprecation_wrapper.py:119] From ..\\libs\\input_data.py:304: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0123 14:47:05.575061 19620 deprecation_wrapper.py:119] From ..\\libs\\input_data.py:305: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\..\\_inputs\\raw\\train\\audio\\_background_noise_\\doing_the_dishes.wav                                                  \n",
      "..\\..\\_inputs\\raw\\train\\audio\\_background_noise_\\dude_miaowing.wav                                                     \n",
      "..\\..\\_inputs\\raw\\train\\audio\\_background_noise_\\exercise_bike.wav                                                     \n",
      "..\\..\\_inputs\\raw\\train\\audio\\_background_noise_\\pink_noise.wav                                                        \n",
      "..\\..\\_inputs\\raw\\train\\audio\\_background_noise_\\running_tap.wav                                                       \n",
      "..\\..\\_inputs\\raw\\train\\audio\\_background_noise_\\white_noise.wav                                                       \n",
      "Tensor(\"AudioSpectrogram:0\", shape=(?, 98, 257), dtype=float32)                                                        \n",
      "  0%|                                                                            | 0/1 [00:03<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0123 14:47:06.181775 19620 deprecation.py:323] From <ipython-input-5-efacab1d1c55>:16: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0123 14:47:06.675554 19620 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0123 14:47:06.703610 19620 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\rnn\\python\\ops\\rnn_cell.py:2242: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0123 14:47:06.770698 19620 deprecation.py:323] From <ipython-input-5-efacab1d1c55>:17: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "W0123 14:47:09.267771 19620 deprecation.py:323] From <ipython-input-5-efacab1d1c55>:48: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0123 14:47:09.425169 19620 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0123 14:47:10.596685 19620 deprecation.py:323] From <ipython-input-5-efacab1d1c55>:52: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W0123 14:47:11.674924 19620 deprecation.py:506] From <ipython-input-5-efacab1d1c55>:78: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0123 14:47:11.694901 19620 deprecation.py:323] From <ipython-input-5-efacab1d1c55>:81: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0123 14:47:12.292392 19620 deprecation.py:323] From ..\\libs\\trainer.py:56: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W0123 14:47:12.342193 19620 deprecation_wrapper.py:119] From ..\\libs\\trainer.py:57: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W0123 14:47:12.349885 19620 deprecation_wrapper.py:119] From ..\\libs\\trainer.py:62: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0123 14:47:18.641331 19620 deprecation_wrapper.py:119] From ..\\libs\\trainer.py:67: The name tf.confusion_matrix is deprecated. Please use tf.math.confusion_matrix instead.\n",
      "\n",
      "W0123 14:47:18.774479 19620 deprecation.py:323] From ..\\libs\\trainer.py:70: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "W0123 14:47:18.785378 19620 deprecation_wrapper.py:119] From ..\\libs\\trainer.py:71: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "W0123 14:47:18.793890 19620 deprecation_wrapper.py:119] From ..\\libs\\trainer.py:72: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W0123 14:47:18.794892 19620 deprecation_wrapper.py:119] From ..\\libs\\trainer.py:72: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W0123 14:47:19.072061 19620 deprecation_wrapper.py:119] From ..\\libs\\trainer.py:73: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0123 14:47:20.034886 19620 deprecation_wrapper.py:119] From ..\\libs\\trainer.py:87: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "I0123 14:47:20.036949 19620 trainer.py:87] Training from step: 1 \n",
      "I0123 14:49:36.293565 19620 trainer.py:123] Step #10: rate 0.000100, accuracy 12.1%, cross entropy 2.471358\n",
      "I0123 14:52:20.366198 19620 trainer.py:123] Step #20: rate 0.000100, accuracy 15.2%, cross entropy 2.445957\n",
      "I0123 14:55:05.119014 19620 trainer.py:123] Step #30: rate 0.000100, accuracy 13.7%, cross entropy 2.407812\n",
      "I0123 14:58:05.706875 19620 trainer.py:123] Step #40: rate 0.000100, accuracy 19.9%, cross entropy 2.305495\n",
      "I0123 15:01:11.598882 19620 trainer.py:123] Step #50: rate 0.000100, accuracy 25.4%, cross entropy 2.207557\n",
      "I0123 15:04:17.879664 19620 trainer.py:123] Step #60: rate 0.000100, accuracy 19.1%, cross entropy 2.211621\n",
      "I0123 15:07:32.628327 19620 trainer.py:123] Step #70: rate 0.000100, accuracy 26.2%, cross entropy 2.080779\n",
      "I0123 15:10:40.962327 19620 trainer.py:123] Step #80: rate 0.000100, accuracy 24.6%, cross entropy 2.113996\n",
      "I0123 15:13:45.996985 19620 trainer.py:123] Step #90: rate 0.000100, accuracy 25.8%, cross entropy 2.132812\n",
      "I0123 15:16:57.050607 19620 trainer.py:123] Step #100: rate 0.000100, accuracy 25.0%, cross entropy 2.127945\n",
      "I0123 15:20:04.823161 19620 trainer.py:123] Step #110: rate 0.000100, accuracy 25.8%, cross entropy 2.053714\n",
      "I0123 15:23:08.911005 19620 trainer.py:123] Step #120: rate 0.000100, accuracy 27.0%, cross entropy 2.050434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7fdeef9dab59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhyperopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhyperopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;31m# next line is where the fmin is actually executed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    284\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                     \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"job exception: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    892\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             )\n\u001b[1;32m--> 894\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-35d31fbcbc6f>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     61\u001b[0m                       \u001b[0mstart_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcheckpoint_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                       \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_architecture\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                       summaries_dir=None,dropout=dropout,args=extra_args)\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\_Files\\MyProjects\\ASDS_3\\ASDS_DL\\FinalProject_SpeechRecognition\\src\\libs\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(sess, logits, fingerprint_input, ground_truth_input, get_train_data, get_val_data, training_steps, learning_rate, eval_step_interval, logging_interval, start_checkpoint, checkpoint_interval, model_name, train_dir, summaries_dir, dropout, args)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;31m# Pull the audio samples we'll use for training.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;31m# Modify here to pass whatever argument is required.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mtrain_fingerprints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ground_truth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         feed_dict={\n\u001b[0;32m    107\u001b[0m                 \u001b[0mfingerprint_input\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_fingerprints\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-35d31fbcbc6f>\u001b[0m in \u001b[0;36mget_train_data\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     23\u001b[0m         train_fingerprints, train_ground_truth = audio_processor.get_data(\n\u001b[0;32m     24\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_settings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbackground_frequency\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             background_volume, time_shift_samples, 'training', sess)\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrain_fingerprints\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_ground_truth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\_Files\\MyProjects\\ASDS_3\\ASDS_DL\\FinalProject_SpeechRecognition\\src\\libs\\input_data.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, how_many, offset, model_settings, background_frequency, background_volume_range, time_shift, mode, sess)\u001b[0m\n\u001b[0;32m    479\u001b[0m           \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspectrogram\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 481\u001b[1;33m           \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmfcc_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    482\u001b[0m       \u001b[0mlabel_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_to_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m       \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1354\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model=hyperopt.fmin(objective, space, algo=hyperopt.tpe.suggest, max_evals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best selected Hyperparameters')\n",
    "print(hyperopt.space_eval(space, best_model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
